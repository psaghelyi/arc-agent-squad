{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "title": "Individual Agent Configuration",
  "description": "Schema for individual GRC agent configuration files",
  "type": "object",
  "required": ["id", "name", "description", "capabilities", "use_cases", "specialized_tools", "voice_settings", "personality", "model_settings", "system_prompt_template"],
  "properties": {
    "id": {
      "type": "string",
      "description": "Unique identifier for the agent",
      "pattern": "^[a-z_]+$"
    },
    "name": {
      "type": "string",
      "description": "Display name for the agent"
    },
    "description": {
      "type": "string",
      "description": "Detailed description of the agent's role and purpose"
    },
    "capabilities": {
      "type": "array",
      "description": "List of agent capabilities",
      "items": {
        "type": "string",
        "enum": [
          "question_answering",
          "voice_processing",
          "customer_support",
          "task_assistance",
          "data_analysis",
          "creative_writing"
        ]
      },
      "minItems": 1
    },
    "use_cases": {
      "type": "array",
      "description": "Specific use cases for this agent",
      "items": {
        "type": "string"
      },
      "minItems": 1
    },
    "specialized_tools": {
      "type": "array",
      "description": "Specialized tools available to this agent",
      "items": {
        "type": "string"
      },
      "minItems": 1
    },
    "voice_settings": {
      "type": "object",
      "description": "Voice configuration for speech synthesis",
      "required": ["voice_id", "style", "speed", "pitch"],
      "properties": {
        "voice_id": {
          "type": "string",
          "description": "Amazon Polly voice ID"
        },
        "style": {
          "type": "string",
          "enum": ["conversational", "authoritative", "analytical", "consultative", "formal"],
          "description": "Speaking style"
        },
        "speed": {
          "type": "string",
          "enum": ["slow", "medium", "fast"],
          "description": "Speaking speed"
        },
        "pitch": {
          "type": "string",
          "enum": ["low", "medium", "high"],
          "description": "Voice pitch"
        }
      },
      "additionalProperties": false
    },
    "personality": {
      "type": "object",
      "description": "Agent personality configuration",
      "required": ["tone", "approach", "communication_style", "traits"],
      "properties": {
        "tone": {
          "type": "string",
          "enum": ["warm", "formal", "neutral", "consultative"],
          "description": "Overall communication tone"
        },
        "approach": {
          "type": "string",
          "enum": ["empathetic", "authoritative", "analytical", "strategic"],
          "description": "Problem-solving approach"
        },
        "communication_style": {
          "type": "string",
          "description": "Detailed communication style description"
        },
        "traits": {
          "type": "array",
          "description": "List of personality traits",
          "items": {
            "type": "string"
          },
          "minItems": 1
        }
      },
      "additionalProperties": false
    },
    "model_settings": {
      "type": "object",
      "description": "AI model configuration",
      "required": ["model_id", "model_provider", "inference_config", "memory_enabled", "streaming", "framework", "llm_framework"],
      "properties": {
        "model_id": {
          "type": "string",
          "description": "AI model identifier"
        },
        "model_provider": {
          "type": "string",
          "enum": ["AWS Bedrock", "OpenAI", "Anthropic"],
          "description": "AI model provider"
        },
        "inference_config": {
          "type": "object",
          "description": "Model inference parameters",
          "required": ["maxTokens", "temperature", "topP"],
          "properties": {
            "maxTokens": {
              "type": "integer",
              "minimum": 100,
              "maximum": 200000,
              "description": "Maximum tokens for response"
            },
            "temperature": {
              "type": "number",
              "minimum": 0,
              "maximum": 1,
              "description": "Response creativity/randomness"
            },
            "topP": {
              "type": "number",
              "minimum": 0,
              "maximum": 1,
              "description": "Nucleus sampling parameter"
            },
            "stopSequences": {
              "type": "array",
              "description": "List of sequences that will stop the model generation",
              "items": {
                "type": "string"
              }
            }
          },
          "additionalProperties": true
        },
        "memory_enabled": {
          "type": "boolean",
          "description": "Whether to enable conversation memory"
        },
        "streaming": {
          "type": "boolean",
          "description": "Whether to enable response streaming"
        },
        "framework": {
          "type": "string",
          "description": "Agent framework"
        },
        "llm_framework": {
          "type": "string",
          "description": "LLM framework implementation"
        }
      },
      "additionalProperties": true
    },
    "system_prompt_template": {
      "type": "string",
      "description": "System prompt template for the agent"
    },
    "system_prompt_variables": {
      "type": "object",
      "description": "Variables to be used with the system prompt template",
      "additionalProperties": true
    }
  },
  "additionalProperties": false
} 